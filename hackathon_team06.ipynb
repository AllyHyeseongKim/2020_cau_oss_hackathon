{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hackathon_team06.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1AosAX9DXOlc",
        "67lwEXhUqys1",
        "A-YjppJpXBO9",
        "4aPbgI-c-Kj8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllyHyeseongKim/2020_cau_oss_hackathon/blob/master/hackathon_team06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 5시 (단, 발표자료는 11시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2020_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms5PBBJ1qSC6",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "check = !if [ -d 'dataset/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (check[0] is '0' ):\n",
        "  !mkdir dataset\n",
        "  !wget 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip'\n",
        "  !unzip matlab.zip -d /content/dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "from scipy import io as spio\n",
        "emnist = spio.loadmat(\"/content/dataset/matlab/emnist-balanced.mat\")\n",
        "\n",
        "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
        "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
        "\n",
        "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
        "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
        "\n",
        "# # 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 데이터 28x28 이미지화\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzoB55YUYLj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZ9KWTBP6AI1",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZP4eRmRqgRp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1fdb94e0-a5e7-48d7-e98d-bab81ae7bec7"
      },
      "source": [
        "'''\n",
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Flatten layer: 28 x 28 x 1 image를 784개의 1D vector input으로 변환\n",
        "model.add(keras.layers.Flatten(input_shape=input_shape))\n",
        "\n",
        "# 1st hidden layer: fully-connected layer\n",
        "# (# of inputs = 784, # of outputs = 512, actication fuction = relu)\n",
        "model.add(keras.layers.Dense(512, activation=tf.nn.relu))\n",
        "\n",
        "# 2nd hidden layer: fully-connected layer \n",
        "# (# of inputs = 512, # of outputs = 256, actication fuction = relu)\n",
        "model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "\n",
        "# 3rd hidden layer: fully-connected layer \n",
        "# (# of inputs = 256, # of outputs = 64, actication fuction = relu)\n",
        "model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
        "\n",
        "# Output layer: fully-connected layer \n",
        "# (# of inputs = 64, # of outputs = 47, actication fuction = softmax)\n",
        "model.add(keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = 5, shuffle=True, callbacks=[cp_callback], validation_data=(x_test_after, y_test))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "865/882 [============================>.] - ETA: 0s - loss: 0.9878 - accuracy: 0.7078\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79580, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 3s 3ms/step - loss: 0.9813 - accuracy: 0.7095 - val_loss: 0.6317 - val_accuracy: 0.7958\n",
            "Epoch 2/5\n",
            "869/882 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8235\n",
            "Epoch 00002: val_accuracy improved from 0.79580 to 0.82564, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 3s 3ms/step - loss: 0.5300 - accuracy: 0.8237 - val_loss: 0.5331 - val_accuracy: 0.8256\n",
            "Epoch 3/5\n",
            "873/882 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.8468\n",
            "Epoch 00003: val_accuracy improved from 0.82564 to 0.83979, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 3s 3ms/step - loss: 0.4431 - accuracy: 0.8466 - val_loss: 0.4976 - val_accuracy: 0.8398\n",
            "Epoch 4/5\n",
            "874/882 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8605\n",
            "Epoch 00004: val_accuracy improved from 0.83979 to 0.84021, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 3s 3ms/step - loss: 0.3910 - accuracy: 0.8605 - val_loss: 0.4849 - val_accuracy: 0.8402\n",
            "Epoch 5/5\n",
            "873/882 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.8713\n",
            "Epoch 00005: val_accuracy improved from 0.84021 to 0.84027, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 3s 3ms/step - loss: 0.3525 - accuracy: 0.8713 - val_loss: 0.4842 - val_accuracy: 0.8403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ba4a6afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaztOvtDMM5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e43226c-0951-4c86-f6c3-b45503329084"
      },
      "source": [
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Conv1\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(np.shape(x_train_after[0]))))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D(2, 2))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "# Conv2\n",
        "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D(2, 2))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "# Conv3\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D(2, 2))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "# Conv4\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D(2, 2))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "# Output layer: fully-connected layer \n",
        "# (# of inputs = 64, # of outputs = 47, actication fuction = softmax)\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1, min_lr=1e-4)\n",
        "\n",
        "model.summary()\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = 17, shuffle=True, callbacks=[reduce_lr, cp_callback], validation_data=(x_test_after, y_test))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_220 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_220 (Bat (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_221 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_221 (Bat (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_88 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_222 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_222 (Bat (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_223 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_223 (Bat (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_89 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_224 (Conv2D)          (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_224 (Bat (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_225 (Conv2D)          (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_225 (Bat (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_226 (Conv2D)          (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_226 (Bat (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_90 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_227 (Conv2D)          (None, 3, 3, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_227 (Bat (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_228 (Conv2D)          (None, 3, 3, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_228 (Bat (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_229 (Conv2D)          (None, 3, 3, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_229 (Bat (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 47)                12079     \n",
            "=================================================================\n",
            "Total params: 3,524,335\n",
            "Trainable params: 3,520,495\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n",
            "Epoch 1/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 1.0676 - accuracy: 0.7030\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83048, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 1.0674 - accuracy: 0.7030 - val_loss: 0.5794 - val_accuracy: 0.8305\n",
            "Epoch 2/17\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.8518\n",
            "Epoch 00002: val_accuracy improved from 0.83048 to 0.87282, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.4486 - accuracy: 0.8518 - val_loss: 0.3698 - val_accuracy: 0.8728\n",
            "Epoch 3/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8675\n",
            "Epoch 00003: val_accuracy improved from 0.87282 to 0.88229, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.3936 - accuracy: 0.8674 - val_loss: 0.3557 - val_accuracy: 0.8823\n",
            "Epoch 4/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.3613 - accuracy: 0.8775\n",
            "Epoch 00004: val_accuracy improved from 0.88229 to 0.88787, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.3613 - accuracy: 0.8775 - val_loss: 0.3305 - val_accuracy: 0.8879\n",
            "Epoch 5/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.3448 - accuracy: 0.8814\n",
            "Epoch 00005: val_accuracy improved from 0.88787 to 0.89122, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.3450 - accuracy: 0.8814 - val_loss: 0.3306 - val_accuracy: 0.8912\n",
            "Epoch 6/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8954\n",
            "Epoch 00006: val_accuracy improved from 0.89122 to 0.90048, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2990 - accuracy: 0.8954 - val_loss: 0.2954 - val_accuracy: 0.9005\n",
            "Epoch 7/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8988\n",
            "Epoch 00007: val_accuracy did not improve from 0.90048\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2839 - accuracy: 0.8988 - val_loss: 0.2941 - val_accuracy: 0.9000\n",
            "Epoch 8/17\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.9026\n",
            "Epoch 00008: val_accuracy improved from 0.90048 to 0.90186, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2761 - accuracy: 0.9026 - val_loss: 0.2930 - val_accuracy: 0.9019\n",
            "Epoch 9/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2741 - accuracy: 0.9026\n",
            "Epoch 00009: val_accuracy improved from 0.90186 to 0.90287, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.2741 - accuracy: 0.9026 - val_loss: 0.2922 - val_accuracy: 0.9029\n",
            "Epoch 10/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9047\n",
            "Epoch 00010: val_accuracy did not improve from 0.90287\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2644 - accuracy: 0.9048 - val_loss: 0.3052 - val_accuracy: 0.8994\n",
            "Epoch 11/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9100\n",
            "Epoch 00011: val_accuracy improved from 0.90287 to 0.90330, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.2443 - accuracy: 0.9099 - val_loss: 0.2922 - val_accuracy: 0.9033\n",
            "Epoch 12/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.9145\n",
            "Epoch 00012: val_accuracy improved from 0.90330 to 0.90606, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2317 - accuracy: 0.9145 - val_loss: 0.2914 - val_accuracy: 0.9061\n",
            "Epoch 13/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2235 - accuracy: 0.9160\n",
            "Epoch 00013: val_accuracy improved from 0.90606 to 0.90622, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.2235 - accuracy: 0.9160 - val_loss: 0.2926 - val_accuracy: 0.9062\n",
            "Epoch 14/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9171\n",
            "Epoch 00014: val_accuracy did not improve from 0.90622\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2210 - accuracy: 0.9171 - val_loss: 0.2937 - val_accuracy: 0.9055\n",
            "Epoch 15/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9183\n",
            "Epoch 00015: val_accuracy did not improve from 0.90622\n",
            "882/882 [==============================] - 21s 24ms/step - loss: 0.2184 - accuracy: 0.9183 - val_loss: 0.2960 - val_accuracy: 0.9049\n",
            "Epoch 16/17\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9188\n",
            "Epoch 00016: val_accuracy did not improve from 0.90622\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2175 - accuracy: 0.9188 - val_loss: 0.2953 - val_accuracy: 0.9058\n",
            "Epoch 17/17\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9194\n",
            "Epoch 00017: val_accuracy did not improve from 0.90622\n",
            "882/882 [==============================] - 21s 23ms/step - loss: 0.2145 - accuracy: 0.9193 - val_loss: 0.2967 - val_accuracy: 0.9057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4112d1c6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wi9yznz4qvzK",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team06'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8abcb3d-03e5-4bad-bbae-e343def6535b"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team06'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 2s 4ms/step - loss: 0.2967 - accuracy: 0.9057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29672276973724365, 0.9056915044784546]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    }
  ]
}